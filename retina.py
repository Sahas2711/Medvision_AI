# -*- coding: utf-8 -*-
"""Retina.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nPBS61VhTE6Gt2DhYkgal9h6nfRKUsvR
"""

# remove old extracted folder (optional but clean)
!rm -rf "/content/Diagnosis of Diabetic Retinopathy"

# unzip and overwrite (-o), be quiet (-q)
!unzip -o -q "/content/drive/MyDrive/ACSCHAackthon/Retina.zip" -d "/content"

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = "/content/retino/train"
test_dir = "/content/retino/test"

img_size = (128, 128)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 15,
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    shear_range = 0.1,
    zoom_range = 0.2,
    horizontal_flip = True,
    fill_mode = 'nearest'
)

test_datagen = ImageDataGenerator(rescale = 1./255)

import os
print(os.listdir("/content"))

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout

base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(128,128,3))
base_model.trainable = False

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(train_generator.num_classes, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator
)

loss, acc = model.evaluate(test_generator)
print(f"Test accuracy : {acc*100:2f}%")

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

base_model.trainable = True
for layer in base_model.layers[:30]:
  layer.trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
               loss='categorical_crossentropy',
               metrics=['accuracy'])

history_finetune = model.fit(
     train_generator,
     epochs=5,
     validation_data=test_generator
 )

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator
)